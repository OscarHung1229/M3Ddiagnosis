{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "velvet-phone",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T06:08:58.090957Z",
     "iopub.status.busy": "2021-04-07T06:08:58.089396Z",
     "iopub.status.idle": "2021-04-07T06:08:59.844473Z",
     "shell.execute_reply": "2021-04-07T06:08:59.842883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from circuit import Circuit\n",
    "import numpy as np\n",
    "import dgl.function as fn\n",
    "import random\n",
    "import networkx as nx\n",
    "from utils import *\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "small-dairy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T06:08:59.909271Z",
     "iopub.status.busy": "2021-04-07T06:08:59.903813Z",
     "iopub.status.idle": "2021-04-07T06:09:17.717032Z",
     "shell.execute_reply": "2021-04-07T06:09:17.715481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parsing verilog netlist\n",
      "nodeID: 114029\n",
      "End parsing verilog netlist\n",
      "CPU time: 8.29s\n",
      "\n",
      "Start parsing verilog netlist\n",
      "nodeID: 227962\n",
      "End parsing verilog netlist\n",
      "CPU time: 9.63s\n",
      "\n",
      "Start parsing top verilog netlist\n",
      "End parsing verilog netlist\n",
      "CPU time: 2.89s\n",
      "\n",
      "Start parsing STIL patterns\n",
      "Pass Pattern 0\n",
      "Final Pat\n",
      "End parsing STIL patterns\n",
      "CPU time: 5.82s\n",
      "\n",
      "Graph(num_nodes={'faultSite': 292654, 'topNode': 2048},\n",
      "      num_edges={('faultSite', 'net', 'faultSite'): 356289, ('topNode', 'topEdge', 'faultSite'): 7274880},\n",
      "      metagraph=[('faultSite', 'faultSite', 'net'), ('topNode', 'faultSite', 'topEdge')])\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "preprocess_begin = time.time()\n",
    "\n",
    "design = \"ldpc_GNN\"\n",
    "path = design+\"/heterograph.bin\"\n",
    "\n",
    "cir = Circuit(design)\n",
    "root = \"/home/sh528/M3Ddesigns/\"+design+\"/\"\n",
    "cir.parseHierVerilog(root+\"die0.v\")\n",
    "cir.parseHierVerilog(root+\"die1.v\")\n",
    "cir.parseTop(root+\"top.v\")\n",
    "# cir.parseVerilog(design+\"/\"+design+\".v\")\n",
    "# cir.parsePartition(design+\"/die0.rpt\")\n",
    "stil = design+\"/TDF.stil\"\n",
    "\n",
    "# if False:\n",
    "if os.path.isfile(path):\n",
    "    n_patterns = cir.parseSTIL(stil, -2)\n",
    "    dic, topEdge = backprop(cir)\n",
    "    hg = load_graphs(\"./\"+design+\"/heterograph.bin\")[0][0]\n",
    "else:\n",
    "    n_patterns = cir.parseSTIL(stil)\n",
    "    edge = CreateGraphByFaultSite(cir)\n",
    "    dic, topEdge = backprop(cir)\n",
    "\n",
    "    hg = dgl.heterograph({ ('topNode', 'topEdge', 'faultSite'): topEdge, ('faultSite', 'net', 'faultSite'): edge })\n",
    "    feats = torch.tensor([cir.Node[n].net.feats for n in cir.Node])\n",
    "    hg.nodes['faultSite'].data['feats'] = feats\n",
    "    hg.nodes['faultSite'].data['in_degree'] = hg.in_degrees(etype='net').view(-1,1).float()\n",
    "    hg.nodes['faultSite'].data['out_degree'] = hg.out_degrees(etype='net').view(-1,1).float()\n",
    "    hg.nodes['faultSite'].data['top_degree'] = hg.in_degrees(etype='topEdge').view(-1,1).float()\n",
    "    hg.nodes['faultSite'].data['level'] = getLevel(cir)\n",
    "    hg.nodes['faultSite'].data['loc'] = getLocation(cir, hg.num_nodes('faultSite'))\n",
    "    hg.nodes['faultSite'].data['more'] = addfeatures(cir, hg.num_nodes('faultSite'))\n",
    "    save_graphs(\"./\"+design+\"/heterograph.bin\", hg)\n",
    "    \n",
    "print(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-football",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([114029., 113933.,  64692.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(hg.nodes['faultSite'].data['loc'], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "innocent-amber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T06:09:17.725251Z",
     "iopub.status.busy": "2021-04-07T06:09:17.723889Z",
     "iopub.status.idle": "2021-04-07T06:49:31.962584Z",
     "shell.execute_reply": "2021-04-07T06:49:31.961877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating data\n",
      "Finish generating data\n",
      "Start generating subgraphs\n",
      "End generating subgraphs\n",
      "Number of samples: 10\n",
      "Total CPU time for preprocessing: 232.10093212127686\n"
     ]
    }
   ],
   "source": [
    "start_pat = 186\n",
    "end_pat = 372\n",
    "\n",
    "dataset, dstIDset = getDatasetfromLog(cir, design, dic, hg, n_patterns, 10, start_pat, end_pat)\n",
    "subgraphs = getSubgraphs(hg, dataset, dstIDset, True, start_pat, end_pat)\n",
    "print(\"Number of samples: {}\".format(len(subgraphs)))\n",
    "\n",
    "\n",
    "preprocess_end = time.time()\n",
    "\n",
    "print(\"Total CPU time for preprocessing: {}\".format(preprocess_end-preprocess_begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "formed-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=144, num_edges=269,\n",
      "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64), 'infeats': Scheme(shape=(11,), dtype=torch.float32)}\n",
      "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-reputation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T06:49:31.971447Z",
     "iopub.status.busy": "2021-04-07T06:49:31.970816Z",
     "iopub.status.idle": "2021-04-07T06:49:31.974537Z",
     "shell.execute_reply": "2021-04-07T06:49:31.973989Z"
    }
   },
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "#         self.lin1 = nn.Linear(11,32)\n",
    "        self.conv1 = GraphConv(11, 32)\n",
    "#         self.conv2 = GraphConv(128, 32)\n",
    "        self.conv3 = GraphConv(32, 3)\n",
    "#         self.norm1 = nn.BatchNorm1d(128)\n",
    "#         self.norm2 = nn.BatchNorm1d(32)\n",
    "#         self.classify1 = nn.Linear(3, 32)\n",
    "#         self.classify2 = nn.Linear(64, 3)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "#         h = self.norm1(h)\n",
    "#         h = self.conv2(g, h)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.norm2(h)\n",
    "        h = self.conv3(g, h)\n",
    "#         h = F.relu(h)\n",
    "        g.ndata['h_final'] = h\n",
    "        hg = dgl.mean_nodes(g, 'h_final')\n",
    "        \n",
    "        return hg\n",
    "#         hg = F.softmax(hg, dim=0)\n",
    "#         ratio = torch.sum(in_feat[:, 3:6], dim=0)\n",
    "#         ratio = self.classify1(ratio)\n",
    "#         hg = torch.cat([hg, ratio.unsqueeze(dim=0)], dim=1)\n",
    "# #         print(hg)\n",
    "        \n",
    "# #         hg = self.classify1(hg)\n",
    "# #         hg = F.relu(hg)\n",
    "        \n",
    "#         return self.classify2(hg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "#         self.lin1 = nn.Linear(11,32)\n",
    "        self.gcn1 = GCN()\n",
    "        self.gcn2 = GCN()\n",
    "        self.gcn3 = GCN()\n",
    "#         self.norm1 = nn.BatchNorm1d(128)\n",
    "#         self.norm2 = nn.BatchNorm1d(32)\n",
    "#         self.classify1 = nn.Linear(3, 32)\n",
    "#         self.classify2 = nn.Linear(64, 3)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        \n",
    "        outputs = []\n",
    "        outputs.append(F.softmax(self.gcn1(g, in_feat), dim=1))\n",
    "        outputs.append(F.softmax(self.gcn2(g, in_feat), dim=1))\n",
    "        outputs.append(F.softmax(self.gcn3(g, in_feat), dim=1))\n",
    "        \n",
    "        outputs = torch.cat([F.softmax(self.gcn1(g, in_feat), dim=1), \n",
    "                             F.softmax(self.gcn2(g, in_feat), dim=1), \n",
    "                             F.softmax(self.gcn3(g, in_feat), dim=1)]\n",
    "                            , dim=0)\n",
    "        \n",
    "#         print(outputs)\n",
    "#         print(torch.mean(outputs,0))\n",
    "#         print(torch.mean(outputs,0).unsqueeze(dim=0))\n",
    "        \n",
    "        return torch.mean(outputs,0).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-worst",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T06:49:31.987591Z",
     "iopub.status.busy": "2021-04-07T06:49:31.985965Z",
     "iopub.status.idle": "2021-04-07T06:49:31.991188Z",
     "shell.execute_reply": "2021-04-07T06:49:31.991662Z"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = len(subgraphs)\n",
    "num_train = int(num_examples * 0.7)\n",
    "num_val = int(num_examples * 0.15)\n",
    "\n",
    "random.shuffle(subgraphs)\n",
    "\n",
    "# # Random\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "val_sampler = SubsetRandomSampler(torch.arange(num_train, num_train+num_val))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train+num_val, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    subgraphs, sampler=train_sampler, batch_size=1, drop_last=False)\n",
    "val_dataloader = GraphDataLoader(\n",
    "    subgraphs, sampler=val_sampler, batch_size=1, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(\n",
    "    subgraphs, sampler=test_sampler, batch_size=1, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-thompson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T06:49:32.024406Z",
     "iopub.status.busy": "2021-04-07T06:49:32.017338Z",
     "iopub.status.idle": "2021-04-07T07:08:07.154714Z",
     "shell.execute_reply": "2021-04-07T07:08:07.153232Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_begin = time.time()\n",
    "\n",
    "model = Model().to('cuda')\n",
    "# g = g.to('cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "train_acc_values = []\n",
    "val_acc_values = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    print(\"\\nEpoch %d:\" %epoch)\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    correct = []\n",
    "    incorrect = []\n",
    "\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    num_tests = 0\n",
    "    train_error = np.zeros((3,3))\n",
    "    for g, l in train_dataloader:\n",
    "        g = g.to('cuda')\n",
    "        labels = l.to('cuda')\n",
    "#         g = dgl.add_reverse_edges(g)\n",
    "#         g = dgl.add_self_loop(g)\n",
    "\n",
    "        infeats = g.ndata['infeats']\n",
    "        \n",
    "\n",
    "\n",
    "        pred = model(g, infeats)\n",
    "#         print(pred.shape)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "#         l1_lambda = 0.001\n",
    "#         l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "#         loss = loss + l1_lambda * l1_norm\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += (pred.argmax(1) == labels).sum().item()\n",
    "        train_loss += loss\n",
    "        num_tests += len(labels)\n",
    "        for i in range(len(labels)):\n",
    "                p = pred[i]\n",
    "                l = labels[i]\n",
    "                train_error[p.argmax(0).item()][l.item()] += 1\n",
    "\n",
    "    avg_loss = train_loss/num_tests\n",
    "    avg_acc = train_acc/num_tests\n",
    "    train_loss_values.append(avg_loss)\n",
    "    train_acc_values.append(avg_acc)\n",
    "\n",
    "    print('In epoch {}, train loss: {:.3f}, train acc: {:.3f}'.format(epoch, avg_loss, avg_acc))\n",
    "    print(train_error)\n",
    "#     print(\"Mean correct: {}, Mean incorrect: {}\".format(np.mean(correct), np.mean(incorrect)))\n",
    "\n",
    "    print(\"Validation...\")\n",
    "    val_error = np.zeros((3,3))\n",
    "    model.eval()\n",
    "    correct = []\n",
    "    incorrect = []\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    num_tests = 0\n",
    "\n",
    "#     random.shuffle(val_set)\n",
    "    with torch.no_grad():\n",
    "        for g, l in val_dataloader:\n",
    "            g = g.to('cuda')\n",
    "            labels = l.to('cuda')\n",
    "#             g = dgl.add_reverse_edges(g)\n",
    "#             g = dgl.add_self_loop(g)\n",
    "\n",
    "            infeats = g.ndata['infeats']\n",
    "\n",
    "            pred = model(g, infeats)\n",
    "            loss = F.cross_entropy(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            val_acc += (pred.argmax(1) == labels).sum().item()\n",
    "\n",
    "            val_loss += loss\n",
    "            num_tests += len(labels)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                p = pred[i]\n",
    "                l = labels[i]\n",
    "                val_error[p.argmax(0).item()][l.item()] += 1\n",
    "            \n",
    "    avg_loss = val_loss/num_tests\n",
    "    avg_acc = val_acc/num_tests\n",
    "    val_loss_values.append(avg_loss)\n",
    "    val_acc_values.append(avg_acc)\n",
    "\n",
    "    print('In epoch {}, val loss: {:.3f}, val acc: {:.3f}'.format(epoch, avg_loss, avg_acc))\n",
    "    print(val_error)\n",
    "#     print(\"Mean correct: {}, Mean incorrect: {}\".format(np.mean(correct), np.mean(incorrect)))\n",
    "#     scheduler.step()\n",
    "\n",
    "#     \n",
    "train_end = time.time()\n",
    "print(\"\\nTraining time for {} epochs: {}\\n\".format(epoch+1, train_end-train_begin))\n",
    "    \n",
    "model.eval()\n",
    "test_acc = 0\n",
    "test_loss = 0\n",
    "num_tests = 0\n",
    "test_error = np.zeros((3,3))\n",
    "test_dist = np.zeros((3,3))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for g, l in test_dataloader:\n",
    "        g = g.to('cuda')\n",
    "        labels = l.to('cuda')\n",
    "#         g = dgl.add_reverse_edges(g)\n",
    "#         g = dgl.add_self_loop(g)\n",
    "        infeats = g.ndata['infeats']\n",
    "\n",
    "        pred = model(g, infeats)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        test_acc += (pred.argmax(1) == labels).sum().item()\n",
    "        test_loss += loss\n",
    "        num_tests += len(labels)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "                p = pred[i]\n",
    "                l = labels[i]\n",
    "                test_error[p.argmax(0).item()][l.item()] += 1\n",
    "                smax = F.softmax(p, dim=0)\n",
    "                test_dist[p.argmax(0).item()][l.item()] += abs(smax[p.argmax(0).item()].item() - smax[l.item()].item())\n",
    "\n",
    "\n",
    "avg_loss = test_loss/num_tests\n",
    "avg_acc = test_acc/num_tests\n",
    "\n",
    "print(\"test accuracy: {}\".format(avg_acc))\n",
    "print(test_error)\n",
    "print(test_dist/test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-animation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T07:08:07.178104Z",
     "iopub.status.busy": "2021-04-07T07:08:07.176733Z",
     "iopub.status.idle": "2021-04-07T07:08:07.412159Z",
     "shell.execute_reply": "2021-04-07T07:08:07.413417Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(0,len(train_loss_values),1), train_loss_values,'b', np.arange(0,len(val_loss_values),1), val_loss_values, 'g')\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(0,len(train_acc_values),1), train_acc_values,'b', np.arange(0,len(val_acc_values),1), val_acc_values, 'g')\n",
    "# plt.plot(np.arange(0,25,1), train_acc_values[-25:],'b', np.arange(0,25,1), val_acc_values[-25:], 'g')\n",
    "\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_acc = 0\n",
    "test_loss = 0\n",
    "num_tests = 0\n",
    "test_error = np.zeros((3,3))\n",
    "test_dist = np.zeros((3,3))\n",
    "graphs = []\n",
    "g2 = []\n",
    "gl = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for g, l in test_dataloader:\n",
    "        g = g.to('cuda')\n",
    "        labels = l.to('cuda')\n",
    "#         g = dgl.add_reverse_edges(g)\n",
    "#         g = dgl.add_self_loop(g)\n",
    "        infeats = g.ndata['infeats']\n",
    "        ubg = dgl.unbatch(g)\n",
    "\n",
    "        pred = model(g, infeats)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        test_acc += (pred.argmax(1) == labels).sum().item()\n",
    "        test_loss += loss\n",
    "        num_tests += len(labels)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            p = pred[i]\n",
    "            ll = labels[i]\n",
    "            \n",
    "            if p.argmax(0) != ll and p.argmax(0).item() == 2:\n",
    "                graphs.append(ubg[i].to('cpu'))\n",
    "                gl.append(ll.to('cpu'))\n",
    "            elif p.argmax(0) == ll and p.argmax(0).item() == 2:\n",
    "                g2.append(ubg[i].to('cpu'))\n",
    "\n",
    "avg_loss = test_loss/num_tests\n",
    "avg_acc = test_acc/num_tests\n",
    "\n",
    "print(\"test accuracy: {}\".format(avg_acc))\n",
    "print(test_error)\n",
    "print(test_dist/test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(graphs)):\n",
    "    g1 = graphs[j]\n",
    "    G = dgl.to_networkx(g1)\n",
    "    color_map = []\n",
    "    for i in range(g1.num_nodes()):\n",
    "        if g1.ndata['infeats'][i][3] == 1:\n",
    "            color_map.append('blue')\n",
    "        elif g1.ndata['infeats'][i][4] == 1:\n",
    "            color_map.append('green')\n",
    "        elif g1.ndata['infeats'][i][5] == 1:\n",
    "            color_map.append('red')\n",
    "    nx.draw(G, node_color=color_map, with_labels=True)\n",
    "    print(gl[j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(g2)):\n",
    "    g1 = g2[j]\n",
    "    G = dgl.to_networkx(g1)\n",
    "    color_map = []\n",
    "    for i in range(g1.num_nodes()):\n",
    "        if g1.ndata['infeats'][i][3] == 1:\n",
    "            color_map.append('blue')\n",
    "        elif g1.ndata['infeats'][i][4] == 1:\n",
    "            color_map.append('green')\n",
    "        elif g1.ndata['infeats'][i][5] == 1:\n",
    "            color_map.append('red')\n",
    "    nx.draw(G, node_color=color_map, with_labels=True)\n",
    "#     print(gl[j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
