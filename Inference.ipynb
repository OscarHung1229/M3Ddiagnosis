{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sorted-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from circuit import Circuit\n",
    "import numpy as np\n",
    "import dgl.function as fn\n",
    "import random\n",
    "import networkx as nx\n",
    "from utils import *\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-stationery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parsing verilog netlist\n",
      "nodeID: 492495\n",
      "End parsing verilog netlist\n",
      "CPU time: 6.05s\n",
      "\n",
      "Start parsing verilog netlist\n",
      "nodeID: 897182\n",
      "End parsing verilog netlist\n",
      "CPU time: 4.72s\n",
      "\n",
      "Start parsing top verilog netlist\n",
      "End parsing verilog netlist\n",
      "CPU time: 3.32s\n",
      "\n",
      "Start parsing STIL patterns\n",
      "Pass Pattern 0\n",
      "Final Pat\n",
      "End parsing STIL patterns\n",
      "CPU time: 2.53s\n",
      "\n",
      "Graph(num_nodes={'faultSite': 1184940, 'topNode': 31409},\n",
      "      num_edges={('faultSite', 'net', 'faultSite'): 1354733, ('topNode', 'topEdge', 'faultSite'): 3447617},\n",
      "      metagraph=[('faultSite', 'faultSite', 'net'), ('topNode', 'faultSite', 'topEdge')])\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "preprocess_begin = time.time()\n",
    "\n",
    "design = \"tate_GNN\"\n",
    "path = design+\"/heterograph.bin\"\n",
    "\n",
    "cir = Circuit(design)\n",
    "root = \"/autofs/home/sh528/M3Ddesigns/\"+design+\"/\"\n",
    "cir.parseHierVerilog(root+\"die0.v\")\n",
    "cir.parseHierVerilog(root+\"die1.v\")\n",
    "cir.parseTop(root+\"top.v\")\n",
    "# cir.parseVerilog(design+\"/\"+design+\".v\")\n",
    "# cir.parsePartition(design+\"/die0.rpt\")\n",
    "stil = design+\"/TDF.stil\"\n",
    "\n",
    "# if False:\n",
    "if os.path.isfile(path):\n",
    "    n_patterns = cir.parseSTIL(stil, -2)\n",
    "    dic, topEdge = backprop(cir,False)\n",
    "    hg = load_graphs(path)[0][0]\n",
    "else:\n",
    "    n_patterns = cir.parseSTIL(stil)\n",
    "    edge = CreateGraphByFaultSite(cir)\n",
    "    dic, topEdge = backprop(cir)\n",
    "    \n",
    "\n",
    "    hg = dgl.heterograph({ ('topNode', 'topEdge', 'faultSite'): topEdge, ('faultSite', 'net', 'faultSite'): edge })\n",
    "    feats = torch.tensor([cir.Node[n].net.feats for n in cir.Node])\n",
    "    hg.nodes['faultSite'].data['feats'] = feats\n",
    "    hg.nodes['faultSite'].data['in_degree'] = hg.in_degrees(etype='net').view(-1,1).float()\n",
    "    hg.nodes['faultSite'].data['out_degree'] = hg.out_degrees(etype='net').view(-1,1).float()\n",
    "    hg.nodes['faultSite'].data['top_degree'] = hg.in_degrees(etype='topEdge').view(-1,1).float()\n",
    "    hg.nodes['faultSite'].data['level'] = getLevel(cir)\n",
    "    hg.nodes['faultSite'].data['loc'] = getLocation(cir, hg.num_nodes('faultSite'))\n",
    "    hg.nodes['faultSite'].data['more'] = addfeatures(cir, hg.num_nodes('faultSite'))\n",
    "    save_graphs(path, hg)\n",
    "#     fout = open(design+\"/topNode.dic\", \"w\")\n",
    "#     for n in dic:\n",
    "#         fout.write(\"{},{}\\n\".format(n,dic[n]))\n",
    "    \n",
    "print(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confident-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GraphConv\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, 16)\n",
    "        self.linear1 = nn.Linear(16+3, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        \n",
    "        ratio = torch.sum(g.ndata['infeats'][:,3:6], dim=0)/g.num_nodes()\n",
    "\n",
    "        g.ndata['h_final'] = h\n",
    "        h_final = dgl.readout_nodes(g, 'h_final', op='max')\n",
    "        h_final = F.softmax(h_final, dim=0)\n",
    "        h_final = torch.cat([h_final, ratio.unsqueeze(0)], dim=1)\n",
    "\n",
    "        return self.linear1(h_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beneficial-movie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GraphConv(in=11, out=128, normalization=both, activation=None)\n",
       "  (conv2): GraphConv(in=128, out=16, normalization=both, activation=None)\n",
       "  (linear1): Linear(in_features=19, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = design + \"/saved_model\"\n",
    "model = GCN(11,128,3)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "settled-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSample(cir, design, dic, g, num_patterns, logname, start_pat=0, end_pat=-1):\n",
    "    \n",
    "    \n",
    "    words = logname.split(\"/\")[-1].rsplit(\"_\",2)\n",
    "    gname = words[0]\n",
    "    pname = words[1]\n",
    "\n",
    "#     if words[1].split(\"/\")[-1] == \"nextstate\":\n",
    "#         pname = \"D\"\n",
    "#     elif words[1].split(\"/\")[-1] == \"IQ\":\n",
    "#         pname = \"Q\"\n",
    "\n",
    "    if gname.startswith(\"MIV\") and pname == \"A\":\n",
    "        pname = \"Z\"\n",
    "\n",
    "    dstID = cir.Node[gname+\"_\"+pname].ID\n",
    "    label = -1\n",
    "    if g.nodes['faultSite'].data['loc'][dstID][0] == 1:\n",
    "        label = 0\n",
    "    elif g.nodes['faultSite'].data['loc'][dstID][1] == 1:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "\n",
    "    if not os.path.isfile(logname):\n",
    "        print(\"Logfile does not exist!\")\n",
    "        return 0,0\n",
    "\n",
    "    f2 = open(logname, \"r\")\n",
    "    l2 = f2.readlines()[1:]\n",
    "    f2.close()\n",
    "\n",
    "\n",
    "    num_pat = end_pat-start_pat\n",
    "    success = True\n",
    "    subnodes = []\n",
    "    for fault in l2:\n",
    "        w2 = fault.split()\n",
    "        if len(w2) != 5:\n",
    "            success = False\n",
    "            break\n",
    "        pat = int(w2[0])-1\n",
    "\n",
    "        if pat < start_pat:\n",
    "            continue\n",
    "\n",
    "        if pat >= end_pat:\n",
    "            break\n",
    "\n",
    "        chname = w2[1]\n",
    "        loc = int(w2[2])\n",
    "\n",
    "\n",
    "        chain = cir.scanchains[cir.sopin.index(chname)]\n",
    "        gname = chain[::-1][loc].name\n",
    "        srcID = dic[gname]\n",
    "\n",
    "        tmpnodes =  g.successors(srcID, etype=('topNode', 'topEdge', 'faultSite')).numpy()\n",
    "\n",
    "        if len(subnodes):\n",
    "            tmpnodes = np.intersect1d(subnodes, tmpnodes)\n",
    "\n",
    "        subnodes = np.array([idx for idx in tmpnodes if g.nodes['faultSite'].data['feats'][idx][pat-start_pat] == 1.0])\n",
    "\n",
    "        if not len(subnodes):\n",
    "            break\n",
    "\n",
    "\n",
    "    if not success:\n",
    "        print(\"Not success!\")\n",
    "        return 0,0\n",
    "    if not len(subnodes):\n",
    "        print(\"No candidates!\")\n",
    "        return 0,0\n",
    "\n",
    "    with g.local_scope():\n",
    "        sg = g.subgraph({'faultSite': subnodes})\n",
    "\n",
    "        assert(dstID in sg.ndata[dgl.NID]['faultSite'])\n",
    "\n",
    "        infeats = torch.cat([sg.nodes['faultSite'].data['in_degree'], sg.nodes['faultSite'].data['out_degree'], sg.nodes['faultSite'].data['top_degree']], dim=1)\n",
    "        infeats = torch.cat([infeats, sg.nodes['faultSite'].data['loc']], dim=1)\n",
    "        infeats = torch.cat([infeats, sg.nodes['faultSite'].data['level']], dim=1)\n",
    "        infeats = torch.cat([infeats, sg.nodes['faultSite'].data['more']], dim=1)\n",
    "        infeats = torch.cat([infeats, sg.in_degrees(etype='net').view(-1,1).float()], dim=1)\n",
    "        infeats = torch.cat([infeats, sg.out_degrees(etype='net').view(-1,1).float()], dim=1)\n",
    "\n",
    "        sg = dgl.to_homogeneous(sg)\n",
    "        sg = dgl.add_reverse_edges(sg)\n",
    "        sg.ndata['infeats'] = infeats\n",
    "\n",
    "    sg = dgl.add_self_loop(sg)\n",
    "            \n",
    "    return sg, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "architectural-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acutual Location: 1, Predictied Location: tensor([2])\n",
      "Total CPU time for inferencing: 0.053s\n"
     ]
    }
   ],
   "source": [
    "inference_st = time.time()\n",
    "\n",
    "log = \"U237924_A_stf.log\"\n",
    "logpath = design+\"/Logs_w_MIV/\"+log\n",
    "g, l = getSample(cir, design, dic, hg, n_patterns, logpath, 0, n_patterns)\n",
    "\n",
    "with torch.no_grad():\n",
    "    infeats = g.ndata['infeats']\n",
    "    pred = model(g, infeats)\n",
    "    print(\"Acutual Location: {}, Predictied Location: {}\".format(l, pred.argmax(1)))\n",
    "\n",
    "inference_end = time.time()\n",
    "\n",
    "print(\"Total CPU time for inferencing: {:.3f}s\".format(inference_end-inference_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-bible",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
